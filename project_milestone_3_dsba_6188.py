# -*- coding: utf-8 -*-
"""Project Milestone 3-DSBA 6188

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QoldRKRh1ViMuObThpUgdj1TftpMQIua

## Get the JSONL file from github repo
"""

# Accessing the title 12 JSONL file

!wget https://raw.githubusercontent.com/DagimB/Text_Mining_ecfr_title12/main/ecfr-title-12.jsonl

from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

"""## Convert JSONL file into an array"""

# deletes the first line of the jsonl file and saves the rest as output.jsonl

import json

with open('ecfr-title-12.jsonl', 'r', encoding='utf-8') as infile:
        next(infile)
        with open('/content/drive/My Drive/output.jsonl', 'w', encoding='utf-8') as outfile:
          for line in infile:
            outfile.write(line)

file_path = '/content/drive/My Drive/output.jsonl'

def jsonl_to_array(file_path):
    data = []
    with open(file_path, 'r') as file:
        for line in file:
            # Strip any leading/trailing whitespace and parse JSON
            json_data = json.loads(line.strip())
            data.append(json_data)
    return data

data_array = jsonl_to_array(file_path)

"""## Split array into train and evaluation using train_test_split"""

# see how long the array is
len(data_array)

# Use train_test_split to get an evaluation dataset that is 200 in length

from sklearn.model_selection import train_test_split
train_data, eval_data = train_test_split(data_array, test_size=0.0428, random_state=42)

print(f"Length of eval dataset: {len(eval_data)}")

len(train_data)

"""## Turn the two arrays back into JSONL files for Prodigy"""

def array_to_jsonl(data_array, file_path):
    with open(file_path, 'w') as file:
        for item in data_array:
            json_line = json.dumps(item)
            file.write(json_line + '\n')

file_path = 'eval.jsonl'
array_to_jsonl(eval_data, file_path)

file_path = 'train.jsonl'
array_to_jsonl(train_data, file_path)